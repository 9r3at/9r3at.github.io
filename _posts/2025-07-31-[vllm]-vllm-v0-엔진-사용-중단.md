---
title: "[vLLM] vLLM V0 엔진 사용 중단"
date: 2025-07-31 06:22:00 +0900
categories: [vLLM]
tags: [vLLM]
description: vLLM 아키텍처 설명
toc: true
comments: true
---

## 📌 vLLM V0 사용 중단(deprecation) 공식 안내 (Issue #18571)

### TL;DR

- **지금부터 V0는 기능 동결(frozen)**: 마이너 버그 수정만 허용됨
- **2025년 6월 30일**: V0 주요 기능을 V1으로 마이그레이션 완료
- **2025년 7월 1일 (v0.10.0)**: V0 코드 제거 시작
- **2025년 8월 초 (v0.11.0)**: V0 코드 완전 삭제 및 문서 정리
## 📌 배경 및 이유 (Motivation)

### 1. 코드 복잡성 및 기술 부채 제거

- 현재 V0/V1이 동일한 모델, 설정, 유틸리티 코드를 공유하고 있어 **변경 시 예상치 못한 충돌**이 발생함
- **기여자가 V0 영향도를 파악하기 어렵고**, 유지보수가 느려짐
- V0 제거로 코드베이스를 단순화하고, V1 개발 속도 및 안정성 향상
### 2. 사용자와 기여자 혼란 해소

- 사용자와 AI 도구들이 종종 **V0와 V1 경로를 혼동**함
- 완전 제거 시 코드 경로 혼란 없이 **온보딩 속도와 생산성 향상**
### 3. 테스트 비용 절감

- 현재 **CI 리소스의 상당량이 V0 테스트에 소모**됨
- V0 제거 시 **테스트 시간 절반 이상 절감** 가능 → V1 테스트 커버리지 확대에 집중 가능
## ⏳ 전환 일정 (Transition Plan)

| 시점 | 단계 |
| --- | --- |
| **즉시 (v0.9.0)** | - V0 기능 동결 (버그 수정만 허용)- 새로운 기능 개발 중단 |
| **2025년 6월 30일까지** | - 주요 기능 V1으로 이관 완료:• 모델 지원: Embedding, Mamba 계열• 기능: Logits Processor API, OpenTelemetry API• 하드웨어: Intel CPU, XPU |
| **2025년 7월 1일 (v0.10.0)** | - V0 **사용 중단(deprecation) 공식 선언**- 코드베이스에서 V0 제거 시작 |
| **2025년 8월 초 (v0.11.0)** | - V0 관련 코드 및 테스트 **완전 제거**- 문서 업데이트 및 클린업 완료 |

## ✅ 마이그레이션 완료 예정 기능

- **모델 지원**
- **기능 지원**
- **하드웨어 지원**
## ⚠️ 중단되는 기능 목록

### ⏸️ 임시 중단 (향후 재도입 예정)

| 항목 | 비고 |
| --- | --- |
| Encoder-decoder 모델 | 예: Whisper |
| Draft 기반 speculative decoding | 실험적 기능 |
| Neuron backend | 재도입 예정 |
| HPU backend | Plugin 형태로 재도입 예정 |

### ⛔ 영구 중단

| 항목 | 비고 |
| --- | --- |
| Prompt adapter | 코드 완전 제거 예정 |
| V100 GPU 지원 | V1은 Ampere 이상 GPU 필수 |
| Structured output per-request | 미지원 유지 예정 |

## 🧭 버전 명명 규칙

| 버전 | 설명 |
| --- | --- |
| **v0.9** | V0의 마지막 지원 버전 (기능 동결, 테스트 유지) |
| **v0.10** | V0 코드 제거 시작 버전 |
| **v0.11** | V0 코드가 **완전히 제거된 첫 번째 버전** |

## 📢 커뮤니티 피드백 요청

- **기술적으로 V0가 꼭 필요한 상황**이라면 GitHub Issue에 코멘트를 남겨 주세요
- 사용자의 요구 사항을 최대한 반영하여 전환을 원활하게 진행하려 합니다
👉 Issue #18571 바로가기


